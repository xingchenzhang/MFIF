This is the repository corresponding to the paper "**Deep Learning-based Multi-focus Image Fusion: A Survey and A Comparative Study**" [[Paper]](https://ieeexplore.ieee.org/abstract/document/9428544) published on Transactions on Pattern Analysis and Machine Intelligence. The author is from Imperial College London, UK.

In the paper, 35 MFIF methods have been evaluated using 19 metrics on 63 image pairs.

## Abstract
Multi-focus image fusion (MFIF) is an important area in image processing. Since 2017, deep learning has been introduced to the field of MFIF and various methods have been proposed. However, there is a lack of survey papers that discuss deep learning-based MFIF methods in detail. In this study, we fill this gap by giving a detailed survey on deep learning-based MFIF algorithms, including categories, methods, datasets and evaluation metrics. To the best of our knowledge, this is the first survey paper which focuses on deep learning based approaches in the field of MFIF. Besides, extensive experiments have been conducted to compare the performances of deep learning-based MFIF algorithms with conventional MFIF approaches. By analyzing qualitative and quantitative results, we give some observations on the current status of MFIF and discuss some future prospects of this field.

## Source images
In total, 63 image pairs from three datasets, i.e. Lytro [1], MFFW [2], MFI-WHU [3] are utilized.


## Fused images
2205 images generated using 35 MFIF algorithms are provided.

## Download links of the 35 MFIF methods


- [ASR](https://github.com/yuliu316316/ASR-Fusion)
- [BFMF](https://github.com/uzeful/Boundary-Finding-based-Multi-focus-Image-Fusion)
- [BGSC](https://github.com/smart-media-lab/Multi-focus-image-fusion-using-a-bilateral-gradient-based-sharpness-criterion) 
- [CBF](https://ww2.mathworks.cn/matlabcentral/fileexchange/43781-image-fusion-based-on-pixel-significance-using-cross-bilateral-filter) 
- [CNN](https://github.com/yuliu316316/CNN-Fusion)
- [CSR](https://github.com/yuliu316316/CSR-Fusion)
- [DCT_Corr](https://github.com/mostafaaminnaji/Multi-Focus-Image-Fusion-in-DCT-Domain)
- [DCT_EOL](https://github.com/mostafaaminnaji/Multi-Focus-Image-Fusion-in-DCT-Domain)
- [DSIFT](https://github.com/yuliu316316/DSIFT-MFIF)
- [DRPL](https://github.com/sasky1/DRPL)
- [DWTDE](https://github.com/yuliu316316/DWTDE-Fusion)
- [ECNN](https://github.com/mostafaaminnaji/ECNN) 
- [FusionDN](https://github.com/hanna-xu/FusionDN)
- [GCF](https://github.com/hanna-xu/GCF)
- [GD](https://ww2.mathworks.cn/matlabcentral/fileexchange/48782-multi-exposure-and-multi-focus-image-fusion-in-gradient-domain)
- [GFDF](https://github.com/bitname/Multi-focus-image-fusion-GFDF)
- [GFF](http://xudongkang.weebly.com/)
- [IFCNN](https://github.com/uzeful/IFCNN)
- [IFM](https://ww2.mathworks.cn/matlabcentral/fileexchange/68963-a-demo-for-image-fusion)
- [MADCNN](https://github.com/jtguan/MADCNN)
- [MFF-GAN](https://github.com/HaoZhang1018/MFF-GAN)
- [MFGM](https://github.com/sujoyp/gradient-domain-imagefusion)
- [MFM](https://github.com/JinleiMa/Multi-focus-Image-Fusion-with-Multi-scale-Focus-Measures)
- [MGFF](https://www.mathworks.com/matlabcentral/fileexchange/72451-multi-scale-guided-image-and-video-fusion?s\_tid=prof\_contriblnk) 
- [LP_SR](https://github.com/yuliu316316/MST-SR-Fusion-Toolbox)
- [MWGF](https://github.com/lsauto/MWGF-Fusion)
- [NSCT_SR](https://github.com/yuliu316316/MST-SR-Fusion-Toolbox)
- [PCANet](https://github.com/songxujay/Multi-focus-image-fusion-with-PCA-filters-of-PCANet)
- [PMGI](https://github.com/jiayi-ma/PMGI\_AAAI2020)
- [RP_SR](https://github.com/yuliu316316/MST-SR-Fusion-Toolbox)
- [QB](https://github.com/zhangyu87/Quadtree\_based\_Image\_Fusion)
- [SESF](https://github.com/Keep-Passion/SESF-Fuse)
- [SFMD](https://github.com/xiaohuiben/Multi-focus-fusion)
- [SVDDCT](https://github.com/mostafaaminnaji/Multi-focus-image-fusion-using-Singular-Value-Decomposition-in-DCT-domain)
- [TF](https://github.com/JinleiMa/Twoscale-Fusion)
- [U2Fusion](https://github.com/hanna-xu/U2Fusion)

## Citation
If you find this work useful, please cite this paper:

	@article{zhang2021deep,
	  title={Deep Learning-based Multi-focus Image Fusion: A Survey and A Comparative Study},
	  author={Zhang, Xingchen},
	  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	  year={2021},
	  publisher={IEEE}
	}


## References
[1] M. Nejati, S. Samavi and S. Shirani. Multi-focus image fusion using dictionary-based sparse representation. Information Fusion, vol. 25, pp. 72-84, 2015.

[2] S. Xu, X. Wei, C. Zhang, J. Liu and J. Zhang. MFFW: A new dataset for multi-focus imgae fusion. arXiv, 2020.

[3] H. Zhang, Z. Le, Z. Shao, H. Xu and J. Ma. MFF-GAN: An unsupervised generative adversarial network with adaptive and gradient joint constraints for multi-focus image fusion. Information Fusion, vol. 66, pp. 40-53, 2020.